# =============================================================================
# workflow/Snakefile — checkpoint-safe, fully config-driven (numbered dirs)
# =============================================================================
from snakemake.io import directory
import glob, os

# -----------------------------------------------------------------------------
#  CONFIG & GLOBAL PATHS
# -----------------------------------------------------------------------------
configfile: "config/config.yaml"
RESOURCES = config["resources_dir"]
LOGS      = config["logs_dir"]
RESULTS   = config["results_dir"]

# ---- numbered result sub-directories ----
DOWNLOAD = f"{RESULTS}/1_downloads"
FILTER   = f"{RESULTS}/2_filtered"
EXTRACT  = f"{RESULTS}/3_extracted"
GROUP    = f"{RESULTS}/4_groups"
TREE     = f"{RESULTS}/5_trees"
ANOMALY  = f"{RESULTS}/6_anomaly"
CLEAN    = f"{RESULTS}/7_final_database"

# -----------------------------------------------------------------------------
#  HELPER ── checkpoint-aware group collector
# -----------------------------------------------------------------------------

def groups_from_ckpt(wc):
    """Return list of group IDs AFTER checkpoint has produced group fasta files."""
    cp = checkpoints.group_by_order.get(**wc)
    fa_glob = os.path.join(cp.output.fa_dir, "groups_*.fa")
    return [os.path.splitext(os.path.basename(f))[0] for f in glob.glob(fa_glob)]

# -----------------------------------------------------------------------------
#  STEP-1  DOWNLOAD
# -----------------------------------------------------------------------------

rule download_mtgenomes:
    input:
        lambda wc: config["download"]["accession_list"] if config["download"]["mode"] == "accession" else config["download"]["species_list"]
    params:
        script=lambda wc: config["download"]["scripts"][config["download"]["mode"]]
    output:
        gb_dir = directory(f"{DOWNLOAD}/outputs/gb_files")
    log:
        f"{LOGS}/download_mtgenomes.log"
    shell:
        r"""
        mkdir -p {output.gb_dir}
        python {params.script} -i {input} -o {DOWNLOAD} -e {config[email]} -k {config[api_key]} > {log} 2>&1
        echo "" >> {log}
        echo "Download mode: {config[download][mode]}" >> {log}
        """

# -----------------------------------------------------------------------------
#  STEP-2  FILTER
# -----------------------------------------------------------------------------

rule filter_sequences:
    input:
        gb_dir = f"{DOWNLOAD}/outputs/gb_files"
    params:
        outdir   = FILTER,
        max_seq  = config["filter"]["max_sequences"],
        keep_flags = " ".join([
            "-cf" if config["filter"]["keep_cf"] else "",
            "-sp" if config["filter"]["keep_sp"] else "",
            "-s"  if config["filter"]["keep_subspecies"] else "",
            "-x"  if config["filter"]["keep_hybrid"] else "",
        ]).strip(),
        filter_arg = (
            "-c"
            if config["filter"]["mode"] == "complete"
            else f"-g {config['filter']['gene']} {config['filter']['minlen']}"
        ),
    output:
        gb_dir = directory(f"{FILTER}/outputs/final_sequences_gb")
    log:
        f"{LOGS}/filter_sequences.log"
    shell:
        r"""
        mkdir -p {output.gb_dir}
        python workflow/scripts/filter_sequences.py \
            -i {input.gb_dir} -o {params.outdir} -m {params.max_seq} \
            {params.keep_flags} {params.filter_arg} \
            > {log} 2>&1
        """

# -----------------------------------------------------------------------------
#  STEP-3  EXTRACT
# -----------------------------------------------------------------------------

rule extract_genes:
    input:
        gb_dir = f"{FILTER}/outputs/final_sequences_gb"
    params:
        outdir = EXTRACT,
        gene_arg = ("-g " + " ".join(config["extract"]["genes"])) if config["extract"]["genes"] else "",
    output:
        concat_fa = f"{EXTRACT}/outputs/Concat.fa",
        out_dir   = directory(f"{EXTRACT}/outputs")
    log:
        f"{LOGS}/extract_genes.log"
    shell:
        r"""
        mkdir -p {output.out_dir}
        python workflow/scripts/extract_genes.py -i {input.gb_dir} -o {params.outdir} {params.gene_arg} > {log} 2>&1
        """

# -----------------------------------------------------------------------------
#  STEP-4  GROUP (CHECKPOINT)
# -----------------------------------------------------------------------------

checkpoint group_by_order:
    input:
        fasta = f"{EXTRACT}/outputs/Concat.fa"
    params:
        max_per_file = config["grouping"]["max_per_file"],
        og_flags = ("-og " + " ".join(config["grouping"]["outgroup_ids"])) if config["grouping"]["outgroup_ids"] else "",
    output:
        fa_dir = directory(f"{GROUP}/fa_files")
    log:
        f"{LOGS}/group_by_order.log"
    shell:
        r"""
        mkdir -p {output.fa_dir}
        python workflow/scripts/group_by_order.py -i {input.fasta} -o {output.fa_dir} -m {params.max_per_file} {params.og_flags} > {log} 2>&1
        """

# -----------------------------------------------------------------------------
#  STEP-5  TREE
# -----------------------------------------------------------------------------

rule build_tree_single:
    input:
        fa = f"{GROUP}/fa_files/{{group}}.fa"
    params:
        mafft = config["tree"]["mafft"],
        fasttree = config["tree"]["fasttree"],
        align_dir = f"{TREE}/alignment",
    output:
        nwk = f"{TREE}/fasttree/{{group}}_fasttree.nwk"
    threads: config["tree"]["threads"]
    log:
        f"{LOGS}/build_tree/{{group}}.log"
    shell:
        r"""
        mkdir -p {params.align_dir} {TREE}/fasttree
        {{
            {params.mafft} --thread {threads} {input.fa} > {params.align_dir}/{wildcards.group}_aligned.fa
            {params.fasttree} -fastest -nt {params.align_dir}/{wildcards.group}_aligned.fa > {output.nwk}
        }} > {log} 2>&1
        """

# -----------------------------------------------------------------------------
#  STEP-6  ANOMALY
# -----------------------------------------------------------------------------

rule detect_anomaly_single:
    input:
        tree = f"{TREE}/fasttree/{{group}}_fasttree.nwk"
    params:
        og_flag = ("-og " + ",".join(config["outgroups"])) if config["outgroups"] else "",
        outdir  = ANOMALY
    output:
        txt = f"{ANOMALY}/{{group}}_anomaly.txt",
        pdf = f"{ANOMALY}/{{group}}.pdf"
    log:
        f"{LOGS}/detect_anomaly/{{group}}.log"
    shell:
        r"""
        mkdir -p {params.outdir} {LOGS}/detect_anomaly
        python workflow/scripts/detect_anomaly.py -i {input.tree} -o {params.outdir}/{wildcards.group} {params.og_flag} > {log} 2>&1
        echo "Please manually review the PDF file at {params.outdir}/{wildcards.group}.pdf to confirm the final list of anomalous sequences." >> {log}
        """

# -----------------------------------------------------------------------------
#  STEP-6½  FLAG
# -----------------------------------------------------------------------------

rule anomaly_done:
    input:
        lambda wc: [f"{ANOMALY}/{g}_anomaly.txt" for g in groups_from_ckpt(wc)] +
                   [f"{ANOMALY}/{g}.pdf" for g in groups_from_ckpt(wc)]
    output:
        touch(f"{ANOMALY}/.done")
    shell:
        "echo '[Snakemake] anomaly stage complete – manual review now.' > /dev/null"

# -----------------------------------------------------------------------------
#  STEP-7  CLEAN
# -----------------------------------------------------------------------------

rule clean_database:
    input:
        fa_src    = f"{EXTRACT}/outputs",
        gb_src    = f"{FILTER}/outputs/final_sequences_gb",
        tree_src  = lambda wc: [
            f"{TREE}/fasttree/{g}_fasttree.nwk" for g in groups_from_ckpt(wc)
        ],
        anomalies = lambda wc: [
            f"{ANOMALY}/{g}_anomaly.txt" for g in groups_from_ckpt(wc)
        ]
    params:
        outdir        = CLEAN,
        sim_files     = " ".join(config["similar_files"]),
        tree_list     = lambda wc: " ".join([
            f"{TREE}/fasttree/{g}_fasttree.nwk" for g in groups_from_ckpt(wc)
        ]),
        anomaly_list  = lambda wc: " ".join([
            f"{ANOMALY}/{g}_anomaly.txt" for g in groups_from_ckpt(wc)
        ])
    output:
        final_dir = directory(CLEAN)
    log:
        f"{LOGS}/clean_database.log"
    shell:
        r"""
        mkdir -p {params.outdir}
        python workflow/scripts/clean_by_anomaly.py \
            -i {input.fa_src} {input.gb_src} {params.tree_list} \
            -o {params.outdir} \
            -a {params.anomaly_list} \
            -s {params.sim_files} \
            > {log} 2>&1
        """

# -----------------------------------------------------------------------------
#  FINAL TARGET
# -----------------------------------------------------------------------------

rule all:
    input:
        f"{ANOMALY}/.done"
