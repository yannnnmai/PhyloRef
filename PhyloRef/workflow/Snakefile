# =============================================================================
# workflow/Snakefile — checkpoint-safe, fully config-driven
# =============================================================================
from snakemake.io import directory
import glob, os

# -----------------------------------------------------------------------------
#  CONFIG & GLOBAL PATHS
# -----------------------------------------------------------------------------
configfile: "config/config.yaml"

RESULTS   = config["results_dir"]
LOGS      = config["logs_dir"]
RESOURCES = config["resources_dir"]

# -----------------------------------------------------------------------------
#  HELPER ── checkpoint-aware group collector
# -----------------------------------------------------------------------------

def groups_from_ckpt(wc):
    """Return list of group IDs AFTER checkpoint has produced group fasta files."""
    cp = checkpoints.group_by_order.get(**wc)
    fa_glob = os.path.join(cp.output.fa_dir, "groups_*.fa")
    return [os.path.splitext(os.path.basename(f))[0] for f in glob.glob(fa_glob)]

# -----------------------------------------------------------------------------
#  STEP-1  DOWNLOAD
# -----------------------------------------------------------------------------

rule download_mtgenomes:
    input:
        lambda wc: config["download"]["accession_list"] if config["download"]["mode"] == "accession" else config["download"]["species_list"]
    params:
        script=lambda wc: config["download"]["scripts"][config["download"]["mode"]]
    output:
        gb_dir=directory(f"{RESULTS}/downloads/outputs/gb_files")
    log:
        f"{LOGS}/download_mtgenomes.log"
    shell:
        r"""
        mkdir -p {output.gb_dir}
        python {params.script} -i {input} -o {RESULTS}/downloads -e {config[email]} -k {config[api_key]} > {log} 2>&1
        echo "" >> {log}
        echo "Download mode: {config[download][mode]}" >> {log}
        """

# -----------------------------------------------------------------------------
#  STEP-2  FILTER
# -----------------------------------------------------------------------------

rule filter_sequences:
    input:
        gb_dir=f"{RESULTS}/downloads/outputs/gb_files"
    params:
        outdir   = f"{RESULTS}/filtered",
        max_seq  = config["filter"]["max_sequences"],
        keep_flags = " ".join([
            "-cf" if config["filter"]["keep_cf"] else "",
            "-sp" if config["filter"]["keep_sp"] else "",
            "-s"  if config["filter"]["keep_subspecies"] else "",
            "-x"  if config["filter"]["keep_hybrid"] else "",
        ]).strip(),
        filter_arg = (
            "-c"
            if config["filter"]["mode"] == "complete"
            else f"-g {config['filter']['gene']} {config['filter']['minlen']}"
        ),
    output:
        gb_dir=directory(f"{RESULTS}/filtered/outputs/final_sequences_gb")
    log:
        f"{LOGS}/filter_sequences.log"
    shell:
        r"""
        mkdir -p {output.gb_dir}
        python workflow/scripts/filter_sequences.py \
            -i {input.gb_dir} -o {params.outdir} -m {params.max_seq} \
            {params.keep_flags} {params.filter_arg} \
            > {log} 2>&1
        """

# -----------------------------------------------------------------------------
#  STEP-3  EXTRACT
# -----------------------------------------------------------------------------

rule extract_genes:
    input:
        gb_dir=f"{RESULTS}/filtered/outputs/final_sequences_gb"
    params:
        outdir=f"{RESULTS}/extracted",
        gene_arg=("-g " + " ".join(config["extract"]["genes"])) if config["extract"]["genes"] else "",
    output:
        concat_fa=f"{RESULTS}/extracted/outputs/Concat.fa",
        out_dir=directory(f"{RESULTS}/extracted/outputs")
    log:
        f"{LOGS}/extract_genes.log"
    shell:
        r"""
        mkdir -p {output.out_dir}
        python workflow/scripts/extract_genes.py -i {input.gb_dir} -o {params.outdir} {params.gene_arg} > {log} 2>&1
        """

# -----------------------------------------------------------------------------
#  STEP-4  GROUP (CHECKPOINT)
# -----------------------------------------------------------------------------

checkpoint group_by_order:
    input:
        fasta=f"{RESULTS}/extracted/outputs/Concat.fa"
    params:
        max_per_file=config["grouping"]["max_per_file"],
        og_flags=("-og " + " ".join(config["grouping"]["outgroup_ids"])) if config["grouping"]["outgroup_ids"] else "",
    output:
        fa_dir=directory(f"{RESULTS}/groups/fa_files")
    log:
        f"{LOGS}/group_by_order.log"
    shell:
        r"""
        mkdir -p {output.fa_dir}
        python workflow/scripts/group_by_order.py -i {input.fasta} -o {output.fa_dir} -m {params.max_per_file} {params.og_flags} > {log} 2>&1
        """

# -----------------------------------------------------------------------------
#  STEP-5  TREE
# -----------------------------------------------------------------------------

rule build_tree_single:
    input:
        fa=f"{RESULTS}/groups/fa_files/{{group}}.fa"
    params:
        mafft=config["tree"]["mafft"],
        fasttree=config["tree"]["fasttree"],
        align_dir=f"{RESULTS}/trees/alignment",
    output:
        nwk=f"{RESULTS}/trees/fasttree/{{group}}_fasttree.nwk"
    threads: config["tree"]["threads"]
    log:
        f"{LOGS}/build_tree/{{group}}.log"
    shell:
        r"""
        mkdir -p {params.align_dir} {RESULTS}/trees/fasttree
        {{
            {params.mafft} --thread {threads} {input.fa} > {params.align_dir}/{wildcards.group}_aligned.fa
            {params.fasttree} -fastest -nt {params.align_dir}/{wildcards.group}_aligned.fa > {output.nwk}
        }} > {log} 2>&1
        """

# -----------------------------------------------------------------------------
#  STEP-6  ANOMALY
# -----------------------------------------------------------------------------

rule detect_anomaly_single:
    input:
        tree=f"{RESULTS}/trees/fasttree/{{group}}_fasttree.nwk"
    params:
        og_flag=("-og " + ",".join(config["outgroups"])) if config["outgroups"] else "",
        outdir=f"{RESULTS}/anomaly"
    output:
        txt=f"{RESULTS}/anomaly/{{group}}_anomaly.txt",
        pdf=f"{RESULTS}/anomaly/{{group}}.pdf"
    log:
        f"{LOGS}/detect_anomaly/{{group}}.log"
    shell:
        r"""
        mkdir -p {params.outdir} {LOGS}/detect_anomaly
        python workflow/scripts/detect_anomaly.py -i {input.tree} -o {params.outdir}/{wildcards.group} {params.og_flag} > {log} 2>&1
        echo "Please manually review the PDF file at {params.outdir}/{wildcards.group}.pdf to confirm the final list of anomalous sequences." >> {log}
        """

# -----------------------------------------------------------------------------
#  STEP-6½  FLAG
# -----------------------------------------------------------------------------

rule anomaly_done:
    input:
        lambda wc: [f"{RESULTS}/anomaly/{g}_anomaly.txt" for g in groups_from_ckpt(wc)] +
                   [f"{RESULTS}/anomaly/{g}.pdf" for g in groups_from_ckpt(wc)]
    output:
        touch(f"{RESULTS}/anomaly/.done")
    shell:
        "echo '[Snakemake] anomaly stage complete – manual review now.' > /dev/null"

# -----------------------------------------------------------------------------
#  STEP-7  CLEAN
# -----------------------------------------------------------------------------

rule clean_database:
    input:
        fa_src    = f"{RESULTS}/extracted/outputs",
        gb_src    = f"{RESULTS}/filtered/outputs/final_sequences_gb",
        tree_src  = lambda wc: [
            f"{RESULTS}/trees/fasttree/{g}_fasttree.nwk"
            for g in groups_from_ckpt(wc)
        ],
        anomalies = lambda wc: [
            f"{RESULTS}/anomaly/{g}_anomaly.txt"
            for g in groups_from_ckpt(wc)
        ]
    params:
        outdir        = f"{RESULTS}/final_database",
        sim_files     = " ".join(config["similar_files"]),
        tree_list     = lambda wc: " ".join([
            f"{RESULTS}/trees/fasttree/{g}_fasttree.nwk" for g in groups_from_ckpt(wc)
        ]),
        anomaly_list  = lambda wc: " ".join([
            f"{RESULTS}/anomaly/{g}_anomaly.txt" for g in groups_from_ckpt(wc)
        ])
    output:
        final_dir = directory(f"{RESULTS}/final_database")
    log:
        f"{LOGS}/clean_database.log"
    shell:
        r"""
        mkdir -p {params.outdir}
        python workflow/scripts/clean_by_anomaly.py \
            -i {input.fa_src} {input.gb_src} {params.tree_list} \
            -o {params.outdir} \
            -a {params.anomaly_list} \
            -s {params.sim_files} \
            > {log} 2>&1
        """
        
# -----------------------------------------------------------------------------
#  FINAL TARGET
# -----------------------------------------------------------------------------

rule all:
    input:
        f"{RESULTS}/anomaly/.done"
